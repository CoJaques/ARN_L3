{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Folder = \"pw3_data\"\n",
    "Files = [\"EEG_mouse_data_1.csv\", \"EEG_mouse_data_2.csv\"]\n",
    "\n",
    "# Lecture des données\n",
    "datas = []\n",
    "for file in Files:\n",
    "    datas.append(pd.read_csv(Folder + \"/\" + file))\n",
    "\n",
    "# Concaténation des données\n",
    "mouse1_eeg = pd.concat(datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sélection des features et normalisation des données.\n",
    "\n",
    "J'ai choisi ici de sélectionner des features de manière à ce qu'elles soient les plus pertinentes possibles pour la prédiction de la variable cible. Pour cela, j'ai utilisé la méthode de sélection de features de type \"wrapper\" appelée \"Recursive Feature Elimination\" (RFE) qui consiste à éliminer les features une à une en fonction de leur importance pour la prédiction de la variable cible. J'ai utilisé pour cela un modèle de régression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   amplitude_around_1_Hertz  amplitude_around_5_Hertz  \\\n",
      "0                 -0.209955                  0.818127   \n",
      "1                 -0.183434                  0.740384   \n",
      "2                 -0.143389                  0.036759   \n",
      "3                 -0.443261                 -0.510886   \n",
      "4                 -0.187587                  0.570556   \n",
      "\n",
      "   amplitude_around_9_Hertz  amplitude_around_13_Hertz  \\\n",
      "0                  0.709286                  -0.133015   \n",
      "1                  0.099354                  -0.289620   \n",
      "2                 -0.457418                  -0.426393   \n",
      "3                 -0.465943                   0.431755   \n",
      "4                  0.829106                   0.528520   \n",
      "\n",
      "   amplitude_around_17_Hertz  amplitude_around_21_Hertz  \\\n",
      "0                  -0.356923                   0.046292   \n",
      "1                   0.893280                   1.456953   \n",
      "2                   1.615055                  -0.280723   \n",
      "3                  -0.464970                  -0.643038   \n",
      "4                   1.349163                   1.142469   \n",
      "\n",
      "   amplitude_around_26_Hertz  amplitude_around_30_Hertz  \\\n",
      "0                   0.027963                  -0.737488   \n",
      "1                  -0.119493                   1.276719   \n",
      "2                  -0.611553                  -0.292198   \n",
      "3                   0.181318                  -1.142626   \n",
      "4                   0.722038                   0.153974   \n",
      "\n",
      "   amplitude_around_34_Hertz  amplitude_around_38_Hertz  ...  \\\n",
      "0                   3.588603                  -0.225196  ...   \n",
      "1                  -0.988009                  -0.760906  ...   \n",
      "2                  -1.181536                  -1.174003  ...   \n",
      "3                   1.131791                  -0.970308  ...   \n",
      "4                   0.401841                  -0.180036  ...   \n",
      "\n",
      "   amplitude_around_63_Hertz  amplitude_around_67_Hertz  \\\n",
      "0                  -0.614165                  -0.011298   \n",
      "1                  -0.979405                   2.034203   \n",
      "2                  -0.250777                  -0.914553   \n",
      "3                  -1.126762                  -0.447982   \n",
      "4                  -0.251609                  -0.955284   \n",
      "\n",
      "   amplitude_around_71_Hertz  amplitude_around_76_Hertz  \\\n",
      "0                   0.579361                  -0.757191   \n",
      "1                  -0.767949                  -0.418021   \n",
      "2                  -1.006095                  -0.916607   \n",
      "3                  -0.436532                  -0.180410   \n",
      "4                  -0.514999                   0.472545   \n",
      "\n",
      "   amplitude_around_80_Hertz  amplitude_around_84_Hertz  \\\n",
      "0                  -0.695886                   0.208107   \n",
      "1                   0.547928                  -1.220401   \n",
      "2                  -1.123806                  -0.723460   \n",
      "3                  -0.818964                  -1.062777   \n",
      "4                  -0.642358                  -0.434973   \n",
      "\n",
      "   amplitude_around_88_Hertz  amplitude_around_92_Hertz  \\\n",
      "0                   0.613812                  -0.731088   \n",
      "1                  -0.542838                  -0.862596   \n",
      "2                  -0.647694                  -0.518808   \n",
      "3                  -1.173185                   0.362702   \n",
      "4                  -0.455470                  -0.874739   \n",
      "\n",
      "   amplitude_around_96_Hertz  amplitude_around_101_Hertz  \n",
      "0                  -0.026148                    1.334097  \n",
      "1                  -0.747605                    1.290267  \n",
      "2                   0.067799                    2.124263  \n",
      "3                  -0.757451                   -0.415788  \n",
      "4                  -0.631579                   -1.009175  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Exemple de sélection de 25 caractéristiques réparties uniformément\n",
    "selected_features = np.linspace(1, 101, 25, dtype=int)\n",
    "selected_features = [f'amplitude_around_{i}_Hertz' for i in selected_features]\n",
    "\n",
    "# Extraction des données correspondant aux caractéristiques sélectionnées\n",
    "data_selected = mouse1_eeg[selected_features]\n",
    "\n",
    "# Normalisation des données avec Z-score\n",
    "scaler = StandardScaler()\n",
    "data_normalized = scaler.fit_transform(data_selected)\n",
    "\n",
    "# Conversion en DataFrame pour une utilisation ultérieure\n",
    "data_normalized_df = pd.DataFrame(data_normalized, columns=selected_features)\n",
    "\n",
    "# Affichage des 5 premières lignes du DataFrame\n",
    "print(data_normalized_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim):\n",
    "    mlp = keras.Sequential([\n",
    "        layers.Dense(2, activation=\"tanh\", input_shape=(input_dim,)),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ])\n",
    "\n",
    "    mlp.compile(\n",
    "        optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.99),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29190/2668360709.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data_combined['state'] = data_combined['state'].replace({'n': 0, 'r': 0, 'w': 1})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27242\n",
      "Epoch 1/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2877 - accuracy: 0.8915 - val_loss: 0.2548 - val_accuracy: 0.9044\n",
      "Epoch 2/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2513 - accuracy: 0.9011 - val_loss: 0.2564 - val_accuracy: 0.9027\n",
      "Epoch 3/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2482 - accuracy: 0.8997 - val_loss: 0.2553 - val_accuracy: 0.8886\n",
      "Epoch 4/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2475 - accuracy: 0.8967 - val_loss: 0.2489 - val_accuracy: 0.8929\n",
      "Epoch 5/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2468 - accuracy: 0.8974 - val_loss: 0.2501 - val_accuracy: 0.8990\n",
      "Epoch 6/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2450 - accuracy: 0.8960 - val_loss: 0.2576 - val_accuracy: 0.8906\n",
      "Epoch 7/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2450 - accuracy: 0.8988 - val_loss: 0.2499 - val_accuracy: 0.8950\n",
      "Epoch 8/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2458 - accuracy: 0.8965 - val_loss: 0.2555 - val_accuracy: 0.9017\n",
      "Epoch 9/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2446 - accuracy: 0.9010 - val_loss: 0.2538 - val_accuracy: 0.8909\n",
      "Epoch 10/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.9011 - val_loss: 0.2531 - val_accuracy: 0.8882\n",
      "Epoch 11/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2460 - accuracy: 0.8983 - val_loss: 0.2473 - val_accuracy: 0.9035\n",
      "Epoch 12/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2443 - accuracy: 0.9003 - val_loss: 0.2584 - val_accuracy: 0.8966\n",
      "Epoch 13/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2449 - accuracy: 0.8984 - val_loss: 0.2532 - val_accuracy: 0.9002\n",
      "Epoch 14/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2458 - accuracy: 0.8964 - val_loss: 0.2504 - val_accuracy: 0.8990\n",
      "Epoch 15/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2437 - accuracy: 0.8972 - val_loss: 0.2494 - val_accuracy: 0.9051\n",
      "Epoch 16/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2448 - accuracy: 0.8998 - val_loss: 0.2508 - val_accuracy: 0.9041\n",
      "Epoch 17/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2468 - accuracy: 0.8969 - val_loss: 0.2521 - val_accuracy: 0.8910\n",
      "Epoch 18/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2446 - accuracy: 0.8974 - val_loss: 0.2560 - val_accuracy: 0.8927\n",
      "Epoch 19/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2461 - accuracy: 0.8968 - val_loss: 0.2488 - val_accuracy: 0.9018\n",
      "Epoch 20/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2441 - accuracy: 0.8988 - val_loss: 0.2502 - val_accuracy: 0.8995\n",
      "Epoch 21/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2437 - accuracy: 0.8987 - val_loss: 0.2453 - val_accuracy: 0.8954\n",
      "Epoch 22/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2447 - accuracy: 0.8978 - val_loss: 0.2558 - val_accuracy: 0.8992\n",
      "Epoch 23/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2441 - accuracy: 0.9017 - val_loss: 0.2456 - val_accuracy: 0.9023\n",
      "Epoch 24/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2439 - accuracy: 0.8970 - val_loss: 0.2497 - val_accuracy: 0.9057\n",
      "Epoch 25/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.8984 - val_loss: 0.2530 - val_accuracy: 0.8982\n",
      "Epoch 26/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2447 - accuracy: 0.8995 - val_loss: 0.2509 - val_accuracy: 0.8927\n",
      "Epoch 27/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.8992 - val_loss: 0.2459 - val_accuracy: 0.8993\n",
      "Epoch 28/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.9002 - val_loss: 0.2552 - val_accuracy: 0.8896\n",
      "Epoch 29/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2448 - accuracy: 0.8986 - val_loss: 0.2506 - val_accuracy: 0.8937\n",
      "Epoch 30/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2423 - accuracy: 0.9015 - val_loss: 0.2536 - val_accuracy: 0.8935\n",
      "Epoch 31/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2449 - accuracy: 0.8987 - val_loss: 0.2480 - val_accuracy: 0.9031\n",
      "Epoch 32/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2430 - accuracy: 0.9022 - val_loss: 0.2497 - val_accuracy: 0.9000\n",
      "Epoch 33/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2439 - accuracy: 0.9000 - val_loss: 0.2499 - val_accuracy: 0.9032\n",
      "Epoch 34/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2470 - accuracy: 0.9003 - val_loss: 0.2541 - val_accuracy: 0.9011\n",
      "Epoch 35/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2446 - accuracy: 0.8995 - val_loss: 0.2469 - val_accuracy: 0.9010\n",
      "Epoch 36/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2465 - accuracy: 0.9002 - val_loss: 0.2505 - val_accuracy: 0.8946\n",
      "Epoch 37/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2458 - accuracy: 0.8988 - val_loss: 0.2562 - val_accuracy: 0.8962\n",
      "Epoch 38/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.8973 - val_loss: 0.2498 - val_accuracy: 0.8933\n",
      "Epoch 39/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2473 - accuracy: 0.9000 - val_loss: 0.2496 - val_accuracy: 0.8957\n",
      "Epoch 40/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2464 - accuracy: 0.8978 - val_loss: 0.2509 - val_accuracy: 0.8957\n",
      "Epoch 41/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2481 - accuracy: 0.8939 - val_loss: 0.2499 - val_accuracy: 0.8996\n",
      "Epoch 42/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.8983 - val_loss: 0.2519 - val_accuracy: 0.8975\n",
      "Epoch 43/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2457 - accuracy: 0.8983 - val_loss: 0.2527 - val_accuracy: 0.8998\n",
      "Epoch 44/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.8988 - val_loss: 0.2494 - val_accuracy: 0.8977\n",
      "Epoch 45/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.8997 - val_loss: 0.2476 - val_accuracy: 0.9008\n",
      "Epoch 46/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2430 - accuracy: 0.9008 - val_loss: 0.2495 - val_accuracy: 0.9011\n",
      "Epoch 47/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2443 - accuracy: 0.9017 - val_loss: 0.2500 - val_accuracy: 0.8956\n",
      "Epoch 48/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2469 - accuracy: 0.8986 - val_loss: 0.2505 - val_accuracy: 0.9051\n",
      "Epoch 49/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2436 - accuracy: 0.9002 - val_loss: 0.2585 - val_accuracy: 0.8847\n",
      "Epoch 50/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2458 - accuracy: 0.8983 - val_loss: 0.2495 - val_accuracy: 0.9039\n",
      "Epoch 51/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2426 - accuracy: 0.9007 - val_loss: 0.2502 - val_accuracy: 0.9036\n",
      "Epoch 52/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2454 - accuracy: 0.9002 - val_loss: 0.2479 - val_accuracy: 0.8974\n",
      "Epoch 53/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.9003 - val_loss: 0.2485 - val_accuracy: 0.8923\n",
      "Epoch 54/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2443 - accuracy: 0.9004 - val_loss: 0.2474 - val_accuracy: 0.8988\n",
      "Epoch 55/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2452 - accuracy: 0.8999 - val_loss: 0.2488 - val_accuracy: 0.9060\n",
      "Epoch 56/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2428 - accuracy: 0.9003 - val_loss: 0.2495 - val_accuracy: 0.8983\n",
      "Epoch 57/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.8965 - val_loss: 0.2531 - val_accuracy: 0.9056\n",
      "Epoch 58/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.8995 - val_loss: 0.2493 - val_accuracy: 0.9038\n",
      "Epoch 59/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.8982 - val_loss: 0.2473 - val_accuracy: 0.8960\n",
      "Epoch 60/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.8976 - val_loss: 0.2500 - val_accuracy: 0.9011\n",
      "Epoch 61/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2439 - accuracy: 0.9030 - val_loss: 0.2518 - val_accuracy: 0.9042\n",
      "Epoch 62/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2457 - accuracy: 0.8980 - val_loss: 0.2547 - val_accuracy: 0.8925\n",
      "Epoch 63/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2459 - accuracy: 0.8980 - val_loss: 0.2488 - val_accuracy: 0.9046\n",
      "Epoch 64/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.8988 - val_loss: 0.2504 - val_accuracy: 0.9085\n",
      "Epoch 65/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.8996 - val_loss: 0.2505 - val_accuracy: 0.8988\n",
      "Epoch 66/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2465 - accuracy: 0.8988 - val_loss: 0.2502 - val_accuracy: 0.8934\n",
      "Epoch 67/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2452 - accuracy: 0.8974 - val_loss: 0.2504 - val_accuracy: 0.9049\n",
      "Epoch 68/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2439 - accuracy: 0.8993 - val_loss: 0.2511 - val_accuracy: 0.8924\n",
      "Epoch 69/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2454 - accuracy: 0.8972 - val_loss: 0.2498 - val_accuracy: 0.9005\n",
      "Epoch 70/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2445 - accuracy: 0.9010 - val_loss: 0.2505 - val_accuracy: 0.8966\n",
      "Epoch 71/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2445 - accuracy: 0.9008 - val_loss: 0.2488 - val_accuracy: 0.9016\n",
      "Epoch 72/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2456 - accuracy: 0.8976 - val_loss: 0.2506 - val_accuracy: 0.9089\n",
      "Epoch 73/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2435 - accuracy: 0.9014 - val_loss: 0.2541 - val_accuracy: 0.8900\n",
      "Epoch 74/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.9003 - val_loss: 0.2484 - val_accuracy: 0.8974\n",
      "Epoch 75/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.8995 - val_loss: 0.2519 - val_accuracy: 0.8960\n",
      "Epoch 76/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2480 - accuracy: 0.8947 - val_loss: 0.2498 - val_accuracy: 0.8994\n",
      "Epoch 77/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.8976 - val_loss: 0.2519 - val_accuracy: 0.9065\n",
      "Epoch 78/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.9018 - val_loss: 0.2490 - val_accuracy: 0.9032\n",
      "Epoch 79/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2452 - accuracy: 0.8985 - val_loss: 0.2513 - val_accuracy: 0.8941\n",
      "Epoch 80/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.8991 - val_loss: 0.2477 - val_accuracy: 0.9031\n",
      "Epoch 81/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2445 - accuracy: 0.8989 - val_loss: 0.2474 - val_accuracy: 0.9026\n",
      "Epoch 82/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.8989 - val_loss: 0.2498 - val_accuracy: 0.8984\n",
      "Epoch 83/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2454 - accuracy: 0.8984 - val_loss: 0.2487 - val_accuracy: 0.9071\n",
      "Epoch 84/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.9004 - val_loss: 0.2513 - val_accuracy: 0.8985\n",
      "Epoch 85/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2435 - accuracy: 0.9006 - val_loss: 0.2517 - val_accuracy: 0.8947\n",
      "Epoch 86/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2466 - accuracy: 0.8977 - val_loss: 0.2531 - val_accuracy: 0.8891\n",
      "Epoch 87/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2442 - accuracy: 0.8984 - val_loss: 0.2531 - val_accuracy: 0.9051\n",
      "Epoch 88/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2454 - accuracy: 0.8968 - val_loss: 0.2556 - val_accuracy: 0.8912\n",
      "Epoch 89/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2455 - accuracy: 0.9004 - val_loss: 0.2518 - val_accuracy: 0.8999\n",
      "Epoch 90/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2449 - accuracy: 0.8984 - val_loss: 0.2517 - val_accuracy: 0.8997\n",
      "Epoch 91/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2448 - accuracy: 0.9003 - val_loss: 0.2545 - val_accuracy: 0.8937\n",
      "Epoch 92/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.8983 - val_loss: 0.2509 - val_accuracy: 0.8961\n",
      "Epoch 93/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2445 - accuracy: 0.9000 - val_loss: 0.2504 - val_accuracy: 0.9067\n",
      "Epoch 94/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2454 - accuracy: 0.8999 - val_loss: 0.2471 - val_accuracy: 0.8975\n",
      "Epoch 95/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2443 - accuracy: 0.9002 - val_loss: 0.2512 - val_accuracy: 0.9003\n",
      "Epoch 96/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2457 - accuracy: 0.8986 - val_loss: 0.2500 - val_accuracy: 0.9021\n",
      "Epoch 97/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.8991 - val_loss: 0.2493 - val_accuracy: 0.9018\n",
      "Epoch 98/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2435 - accuracy: 0.8995 - val_loss: 0.2522 - val_accuracy: 0.8927\n",
      "Epoch 99/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2462 - accuracy: 0.8973 - val_loss: 0.2495 - val_accuracy: 0.9026\n",
      "Epoch 100/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2444 - accuracy: 0.8962 - val_loss: 0.2509 - val_accuracy: 0.8946\n",
      "Accuracy: 0.89\n",
      "27242\n",
      "Epoch 1/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2852 - accuracy: 0.8950 - val_loss: 0.2603 - val_accuracy: 0.9002\n",
      "Epoch 2/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2471 - accuracy: 0.8996 - val_loss: 0.2596 - val_accuracy: 0.8887\n",
      "Epoch 3/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.9016 - val_loss: 0.2521 - val_accuracy: 0.8982\n",
      "Epoch 4/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2456 - accuracy: 0.9018 - val_loss: 0.2526 - val_accuracy: 0.9038\n",
      "Epoch 5/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2431 - accuracy: 0.9006 - val_loss: 0.2492 - val_accuracy: 0.9010\n",
      "Epoch 6/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2433 - accuracy: 0.9032 - val_loss: 0.2518 - val_accuracy: 0.9004\n",
      "Epoch 7/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.8995 - val_loss: 0.2528 - val_accuracy: 0.9000\n",
      "Epoch 8/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2437 - accuracy: 0.9016 - val_loss: 0.2542 - val_accuracy: 0.9040\n",
      "Epoch 9/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.9030 - val_loss: 0.2563 - val_accuracy: 0.8947\n",
      "Epoch 10/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2447 - accuracy: 0.9004 - val_loss: 0.2499 - val_accuracy: 0.8998\n",
      "Epoch 11/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2425 - accuracy: 0.9032 - val_loss: 0.2502 - val_accuracy: 0.8908\n",
      "Epoch 12/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2448 - accuracy: 0.9009 - val_loss: 0.2498 - val_accuracy: 0.8927\n",
      "Epoch 13/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2450 - accuracy: 0.8988 - val_loss: 0.2522 - val_accuracy: 0.8855\n",
      "Epoch 14/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2436 - accuracy: 0.9009 - val_loss: 0.2488 - val_accuracy: 0.8957\n",
      "Epoch 15/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2455 - accuracy: 0.9011 - val_loss: 0.2535 - val_accuracy: 0.8988\n",
      "Epoch 16/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2452 - accuracy: 0.8999 - val_loss: 0.2573 - val_accuracy: 0.8934\n",
      "Epoch 17/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2452 - accuracy: 0.9002 - val_loss: 0.2515 - val_accuracy: 0.8962\n",
      "Epoch 18/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2444 - accuracy: 0.9011 - val_loss: 0.2493 - val_accuracy: 0.8974\n",
      "Epoch 19/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2434 - accuracy: 0.9013 - val_loss: 0.2491 - val_accuracy: 0.8966\n",
      "Epoch 20/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2435 - accuracy: 0.9015 - val_loss: 0.2489 - val_accuracy: 0.9045\n",
      "Epoch 21/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2450 - accuracy: 0.8997 - val_loss: 0.2520 - val_accuracy: 0.9032\n",
      "Epoch 22/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2449 - accuracy: 0.9010 - val_loss: 0.2504 - val_accuracy: 0.9036\n",
      "Epoch 23/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.9014 - val_loss: 0.2543 - val_accuracy: 0.8912\n",
      "Epoch 24/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2429 - accuracy: 0.9019 - val_loss: 0.2494 - val_accuracy: 0.8935\n",
      "Epoch 25/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2452 - accuracy: 0.8976 - val_loss: 0.2487 - val_accuracy: 0.8954\n",
      "Epoch 26/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2435 - accuracy: 0.9022 - val_loss: 0.2506 - val_accuracy: 0.9035\n",
      "Epoch 27/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.9016 - val_loss: 0.2502 - val_accuracy: 0.9044\n",
      "Epoch 28/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2413 - accuracy: 0.9029 - val_loss: 0.2573 - val_accuracy: 0.8957\n",
      "Epoch 29/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2450 - accuracy: 0.9028 - val_loss: 0.2495 - val_accuracy: 0.9016\n",
      "Epoch 30/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.9018 - val_loss: 0.2485 - val_accuracy: 0.8984\n",
      "Epoch 31/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2441 - accuracy: 0.9021 - val_loss: 0.2495 - val_accuracy: 0.9046\n",
      "Epoch 32/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2435 - accuracy: 0.9020 - val_loss: 0.2523 - val_accuracy: 0.8901\n",
      "Epoch 33/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2455 - accuracy: 0.9025 - val_loss: 0.2533 - val_accuracy: 0.8973\n",
      "Epoch 34/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2431 - accuracy: 0.9009 - val_loss: 0.2502 - val_accuracy: 0.9027\n",
      "Epoch 35/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2425 - accuracy: 0.9022 - val_loss: 0.2503 - val_accuracy: 0.8964\n",
      "Epoch 36/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2424 - accuracy: 0.9028 - val_loss: 0.2499 - val_accuracy: 0.8932\n",
      "Epoch 37/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2427 - accuracy: 0.9012 - val_loss: 0.2494 - val_accuracy: 0.9019\n",
      "Epoch 38/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2442 - accuracy: 0.9032 - val_loss: 0.2492 - val_accuracy: 0.8992\n",
      "Epoch 39/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2427 - accuracy: 0.9010 - val_loss: 0.2505 - val_accuracy: 0.8927\n",
      "Epoch 40/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2439 - accuracy: 0.9046 - val_loss: 0.2509 - val_accuracy: 0.8915\n",
      "Epoch 41/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2428 - accuracy: 0.9015 - val_loss: 0.2487 - val_accuracy: 0.8982\n",
      "Epoch 42/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2443 - accuracy: 0.9024 - val_loss: 0.2547 - val_accuracy: 0.9026\n",
      "Epoch 43/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2441 - accuracy: 0.9032 - val_loss: 0.2510 - val_accuracy: 0.8907\n",
      "Epoch 44/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2457 - accuracy: 0.8993 - val_loss: 0.2515 - val_accuracy: 0.8958\n",
      "Epoch 45/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.9022 - val_loss: 0.2516 - val_accuracy: 0.8922\n",
      "Epoch 46/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2442 - accuracy: 0.9027 - val_loss: 0.2499 - val_accuracy: 0.8980\n",
      "Epoch 47/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2445 - accuracy: 0.9022 - val_loss: 0.2506 - val_accuracy: 0.8953\n",
      "Epoch 48/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2462 - accuracy: 0.8992 - val_loss: 0.2549 - val_accuracy: 0.8836\n",
      "Epoch 49/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.9018 - val_loss: 0.2529 - val_accuracy: 0.8998\n",
      "Epoch 50/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2449 - accuracy: 0.9007 - val_loss: 0.2493 - val_accuracy: 0.8976\n",
      "Epoch 51/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2435 - accuracy: 0.9008 - val_loss: 0.2499 - val_accuracy: 0.9010\n",
      "Epoch 52/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2430 - accuracy: 0.9010 - val_loss: 0.2511 - val_accuracy: 0.8980\n",
      "Epoch 53/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.9030 - val_loss: 0.2566 - val_accuracy: 0.8853\n",
      "Epoch 54/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2446 - accuracy: 0.9015 - val_loss: 0.2530 - val_accuracy: 0.8952\n",
      "Epoch 55/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2434 - accuracy: 0.9023 - val_loss: 0.2541 - val_accuracy: 0.9018\n",
      "Epoch 56/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.9015 - val_loss: 0.2531 - val_accuracy: 0.8957\n",
      "Epoch 57/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2456 - accuracy: 0.8999 - val_loss: 0.2532 - val_accuracy: 0.8932\n",
      "Epoch 58/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2436 - accuracy: 0.9028 - val_loss: 0.2501 - val_accuracy: 0.9011\n",
      "Epoch 59/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.9016 - val_loss: 0.2484 - val_accuracy: 0.8988\n",
      "Epoch 60/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2439 - accuracy: 0.8998 - val_loss: 0.2519 - val_accuracy: 0.8957\n",
      "Epoch 61/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2450 - accuracy: 0.8984 - val_loss: 0.2507 - val_accuracy: 0.8972\n",
      "Epoch 62/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.9018 - val_loss: 0.2502 - val_accuracy: 0.9032\n",
      "Epoch 63/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2450 - accuracy: 0.9015 - val_loss: 0.2538 - val_accuracy: 0.8899\n",
      "Epoch 64/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.9007 - val_loss: 0.2483 - val_accuracy: 0.8996\n",
      "Epoch 65/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2434 - accuracy: 0.9010 - val_loss: 0.2505 - val_accuracy: 0.8963\n",
      "Epoch 66/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2426 - accuracy: 0.9008 - val_loss: 0.2465 - val_accuracy: 0.9039\n",
      "Epoch 67/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2419 - accuracy: 0.9028 - val_loss: 0.2509 - val_accuracy: 0.9019\n",
      "Epoch 68/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2465 - accuracy: 0.8988 - val_loss: 0.2499 - val_accuracy: 0.8895\n",
      "Epoch 69/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.9018 - val_loss: 0.2498 - val_accuracy: 0.8965\n",
      "Epoch 70/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2436 - accuracy: 0.9008 - val_loss: 0.2519 - val_accuracy: 0.8969\n",
      "Epoch 71/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.9021 - val_loss: 0.2554 - val_accuracy: 0.8869\n",
      "Epoch 72/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2442 - accuracy: 0.9015 - val_loss: 0.2493 - val_accuracy: 0.9035\n",
      "Epoch 73/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2441 - accuracy: 0.9022 - val_loss: 0.2507 - val_accuracy: 0.8955\n",
      "Epoch 74/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2428 - accuracy: 0.9025 - val_loss: 0.2528 - val_accuracy: 0.8935\n",
      "Epoch 75/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.9010 - val_loss: 0.2505 - val_accuracy: 0.8992\n",
      "Epoch 76/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2437 - accuracy: 0.9005 - val_loss: 0.2515 - val_accuracy: 0.9014\n",
      "Epoch 77/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2460 - accuracy: 0.8999 - val_loss: 0.2526 - val_accuracy: 0.8950\n",
      "Epoch 78/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2424 - accuracy: 0.9022 - val_loss: 0.2545 - val_accuracy: 0.8915\n",
      "Epoch 79/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.9007 - val_loss: 0.2527 - val_accuracy: 0.8979\n",
      "Epoch 80/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2430 - accuracy: 0.9022 - val_loss: 0.2514 - val_accuracy: 0.8949\n",
      "Epoch 81/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2449 - accuracy: 0.9002 - val_loss: 0.2518 - val_accuracy: 0.8933\n",
      "Epoch 82/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2441 - accuracy: 0.9030 - val_loss: 0.2503 - val_accuracy: 0.8969\n",
      "Epoch 83/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2442 - accuracy: 0.8991 - val_loss: 0.2605 - val_accuracy: 0.8880\n",
      "Epoch 84/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2433 - accuracy: 0.8999 - val_loss: 0.2487 - val_accuracy: 0.9007\n",
      "Epoch 85/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2433 - accuracy: 0.9025 - val_loss: 0.2471 - val_accuracy: 0.9026\n",
      "Epoch 86/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2445 - accuracy: 0.9036 - val_loss: 0.2493 - val_accuracy: 0.8935\n",
      "Epoch 87/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2467 - accuracy: 0.8994 - val_loss: 0.2498 - val_accuracy: 0.8971\n",
      "Epoch 88/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2449 - accuracy: 0.9017 - val_loss: 0.2510 - val_accuracy: 0.8965\n",
      "Epoch 89/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2448 - accuracy: 0.9021 - val_loss: 0.2511 - val_accuracy: 0.9002\n",
      "Epoch 90/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2446 - accuracy: 0.9008 - val_loss: 0.2521 - val_accuracy: 0.8916\n",
      "Epoch 91/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2434 - accuracy: 0.9031 - val_loss: 0.2451 - val_accuracy: 0.9018\n",
      "Epoch 92/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.9001 - val_loss: 0.2552 - val_accuracy: 0.8917\n",
      "Epoch 93/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2447 - accuracy: 0.8977 - val_loss: 0.2537 - val_accuracy: 0.8859\n",
      "Epoch 94/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2448 - accuracy: 0.9010 - val_loss: 0.2495 - val_accuracy: 0.8987\n",
      "Epoch 95/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2444 - accuracy: 0.9025 - val_loss: 0.2534 - val_accuracy: 0.8981\n",
      "Epoch 96/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2439 - accuracy: 0.9022 - val_loss: 0.2511 - val_accuracy: 0.9054\n",
      "Epoch 97/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2442 - accuracy: 0.8995 - val_loss: 0.2600 - val_accuracy: 0.8900\n",
      "Epoch 98/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2452 - accuracy: 0.9018 - val_loss: 0.2491 - val_accuracy: 0.8949\n",
      "Epoch 99/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.9024 - val_loss: 0.2520 - val_accuracy: 0.8977\n",
      "Epoch 100/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.9017 - val_loss: 0.2476 - val_accuracy: 0.8996\n",
      "Accuracy: 0.90\n",
      "27242\n",
      "Epoch 1/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2825 - accuracy: 0.8928 - val_loss: 0.2520 - val_accuracy: 0.9008\n",
      "Epoch 2/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2578 - accuracy: 0.8980 - val_loss: 0.2523 - val_accuracy: 0.8997\n",
      "Epoch 3/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2566 - accuracy: 0.8985 - val_loss: 0.2484 - val_accuracy: 0.8993\n",
      "Epoch 4/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2539 - accuracy: 0.8995 - val_loss: 0.2464 - val_accuracy: 0.9101\n",
      "Epoch 5/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2538 - accuracy: 0.8991 - val_loss: 0.2511 - val_accuracy: 0.8972\n",
      "Epoch 6/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2529 - accuracy: 0.8993 - val_loss: 0.2416 - val_accuracy: 0.9065\n",
      "Epoch 7/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2539 - accuracy: 0.8973 - val_loss: 0.2476 - val_accuracy: 0.8980\n",
      "Epoch 8/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2510 - accuracy: 0.8989 - val_loss: 0.2407 - val_accuracy: 0.9067\n",
      "Epoch 9/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2528 - accuracy: 0.8984 - val_loss: 0.2417 - val_accuracy: 0.8997\n",
      "Epoch 10/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2502 - accuracy: 0.8985 - val_loss: 0.2481 - val_accuracy: 0.9079\n",
      "Epoch 11/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2528 - accuracy: 0.8946 - val_loss: 0.2450 - val_accuracy: 0.8888\n",
      "Epoch 12/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2520 - accuracy: 0.8966 - val_loss: 0.2435 - val_accuracy: 0.8973\n",
      "Epoch 13/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2543 - accuracy: 0.8932 - val_loss: 0.2400 - val_accuracy: 0.9066\n",
      "Epoch 14/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2518 - accuracy: 0.8975 - val_loss: 0.2395 - val_accuracy: 0.9048\n",
      "Epoch 15/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2525 - accuracy: 0.8940 - val_loss: 0.2429 - val_accuracy: 0.9007\n",
      "Epoch 16/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2508 - accuracy: 0.8982 - val_loss: 0.2425 - val_accuracy: 0.9020\n",
      "Epoch 17/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2512 - accuracy: 0.8982 - val_loss: 0.2385 - val_accuracy: 0.9093\n",
      "Epoch 18/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2502 - accuracy: 0.8962 - val_loss: 0.2380 - val_accuracy: 0.9069\n",
      "Epoch 19/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2513 - accuracy: 0.8962 - val_loss: 0.2371 - val_accuracy: 0.9073\n",
      "Epoch 20/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2519 - accuracy: 0.8978 - val_loss: 0.2398 - val_accuracy: 0.8960\n",
      "Epoch 21/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2500 - accuracy: 0.8985 - val_loss: 0.2368 - val_accuracy: 0.9072\n",
      "Epoch 22/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2497 - accuracy: 0.8964 - val_loss: 0.2373 - val_accuracy: 0.9079\n",
      "Epoch 23/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2510 - accuracy: 0.8986 - val_loss: 0.2381 - val_accuracy: 0.9048\n",
      "Epoch 24/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2511 - accuracy: 0.8985 - val_loss: 0.2429 - val_accuracy: 0.8962\n",
      "Epoch 25/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2541 - accuracy: 0.8955 - val_loss: 0.2367 - val_accuracy: 0.9068\n",
      "Epoch 26/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2513 - accuracy: 0.8971 - val_loss: 0.2461 - val_accuracy: 0.8975\n",
      "Epoch 27/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2513 - accuracy: 0.8982 - val_loss: 0.2384 - val_accuracy: 0.8945\n",
      "Epoch 28/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2489 - accuracy: 0.8991 - val_loss: 0.2440 - val_accuracy: 0.9037\n",
      "Epoch 29/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2502 - accuracy: 0.9002 - val_loss: 0.2366 - val_accuracy: 0.8942\n",
      "Epoch 30/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2516 - accuracy: 0.8988 - val_loss: 0.2383 - val_accuracy: 0.8988\n",
      "Epoch 31/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2509 - accuracy: 0.8958 - val_loss: 0.2352 - val_accuracy: 0.9028\n",
      "Epoch 32/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2497 - accuracy: 0.8998 - val_loss: 0.2396 - val_accuracy: 0.9022\n",
      "Epoch 33/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2508 - accuracy: 0.8992 - val_loss: 0.2369 - val_accuracy: 0.9079\n",
      "Epoch 34/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2506 - accuracy: 0.8975 - val_loss: 0.2385 - val_accuracy: 0.9077\n",
      "Epoch 35/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2493 - accuracy: 0.8962 - val_loss: 0.2478 - val_accuracy: 0.8881\n",
      "Epoch 36/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2501 - accuracy: 0.8991 - val_loss: 0.2376 - val_accuracy: 0.9060\n",
      "Epoch 37/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2490 - accuracy: 0.8985 - val_loss: 0.2381 - val_accuracy: 0.9096\n",
      "Epoch 38/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2516 - accuracy: 0.8961 - val_loss: 0.2444 - val_accuracy: 0.9035\n",
      "Epoch 39/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2521 - accuracy: 0.8961 - val_loss: 0.2380 - val_accuracy: 0.8997\n",
      "Epoch 40/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2511 - accuracy: 0.8969 - val_loss: 0.2387 - val_accuracy: 0.8991\n",
      "Epoch 41/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2522 - accuracy: 0.8990 - val_loss: 0.2389 - val_accuracy: 0.9008\n",
      "Epoch 42/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2509 - accuracy: 0.8985 - val_loss: 0.2378 - val_accuracy: 0.9036\n",
      "Epoch 43/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2490 - accuracy: 0.8999 - val_loss: 0.2341 - val_accuracy: 0.9086\n",
      "Epoch 44/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2502 - accuracy: 0.8981 - val_loss: 0.2383 - val_accuracy: 0.8959\n",
      "Epoch 45/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2507 - accuracy: 0.8992 - val_loss: 0.2396 - val_accuracy: 0.9070\n",
      "Epoch 46/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2505 - accuracy: 0.8989 - val_loss: 0.2367 - val_accuracy: 0.9033\n",
      "Epoch 47/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2499 - accuracy: 0.8997 - val_loss: 0.2375 - val_accuracy: 0.8986\n",
      "Epoch 48/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2505 - accuracy: 0.8994 - val_loss: 0.2389 - val_accuracy: 0.8968\n",
      "Epoch 49/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2490 - accuracy: 0.8995 - val_loss: 0.2390 - val_accuracy: 0.9007\n",
      "Epoch 50/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2496 - accuracy: 0.9009 - val_loss: 0.2419 - val_accuracy: 0.8935\n",
      "Epoch 51/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2494 - accuracy: 0.8993 - val_loss: 0.2366 - val_accuracy: 0.9093\n",
      "Epoch 52/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2515 - accuracy: 0.8973 - val_loss: 0.2376 - val_accuracy: 0.9043\n",
      "Epoch 53/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2504 - accuracy: 0.8996 - val_loss: 0.2345 - val_accuracy: 0.9060\n",
      "Epoch 54/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2507 - accuracy: 0.8980 - val_loss: 0.2358 - val_accuracy: 0.9003\n",
      "Epoch 55/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2498 - accuracy: 0.8980 - val_loss: 0.2389 - val_accuracy: 0.8998\n",
      "Epoch 56/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2506 - accuracy: 0.8999 - val_loss: 0.2338 - val_accuracy: 0.9021\n",
      "Epoch 57/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2515 - accuracy: 0.8961 - val_loss: 0.2426 - val_accuracy: 0.9048\n",
      "Epoch 58/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2522 - accuracy: 0.8978 - val_loss: 0.2427 - val_accuracy: 0.8962\n",
      "Epoch 59/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2485 - accuracy: 0.9004 - val_loss: 0.2382 - val_accuracy: 0.9036\n",
      "Epoch 60/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2498 - accuracy: 0.8977 - val_loss: 0.2400 - val_accuracy: 0.9062\n",
      "Epoch 61/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2494 - accuracy: 0.9003 - val_loss: 0.2378 - val_accuracy: 0.9004\n",
      "Epoch 62/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2506 - accuracy: 0.8964 - val_loss: 0.2371 - val_accuracy: 0.9049\n",
      "Epoch 63/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2504 - accuracy: 0.8983 - val_loss: 0.2431 - val_accuracy: 0.9015\n",
      "Epoch 64/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2499 - accuracy: 0.8977 - val_loss: 0.2370 - val_accuracy: 0.9107\n",
      "Epoch 65/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2502 - accuracy: 0.8998 - val_loss: 0.2376 - val_accuracy: 0.9050\n",
      "Epoch 66/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2489 - accuracy: 0.9012 - val_loss: 0.2364 - val_accuracy: 0.9075\n",
      "Epoch 67/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2502 - accuracy: 0.9006 - val_loss: 0.2378 - val_accuracy: 0.9068\n",
      "Epoch 68/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2510 - accuracy: 0.8963 - val_loss: 0.2332 - val_accuracy: 0.9064\n",
      "Epoch 69/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2483 - accuracy: 0.9015 - val_loss: 0.2334 - val_accuracy: 0.9108\n",
      "Epoch 70/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2490 - accuracy: 0.8983 - val_loss: 0.2369 - val_accuracy: 0.9055\n",
      "Epoch 71/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2499 - accuracy: 0.8995 - val_loss: 0.2340 - val_accuracy: 0.9086\n",
      "Epoch 72/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2500 - accuracy: 0.8977 - val_loss: 0.2385 - val_accuracy: 0.9082\n",
      "Epoch 73/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2509 - accuracy: 0.8988 - val_loss: 0.2415 - val_accuracy: 0.8977\n",
      "Epoch 74/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2499 - accuracy: 0.8983 - val_loss: 0.2395 - val_accuracy: 0.8997\n",
      "Epoch 75/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2503 - accuracy: 0.8988 - val_loss: 0.2381 - val_accuracy: 0.9057\n",
      "Epoch 76/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2504 - accuracy: 0.8982 - val_loss: 0.2357 - val_accuracy: 0.9107\n",
      "Epoch 77/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2509 - accuracy: 0.8977 - val_loss: 0.2348 - val_accuracy: 0.9104\n",
      "Epoch 78/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2477 - accuracy: 0.9027 - val_loss: 0.2367 - val_accuracy: 0.9021\n",
      "Epoch 79/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2508 - accuracy: 0.8978 - val_loss: 0.2401 - val_accuracy: 0.8941\n",
      "Epoch 80/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2494 - accuracy: 0.8973 - val_loss: 0.2368 - val_accuracy: 0.9043\n",
      "Epoch 81/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2487 - accuracy: 0.8988 - val_loss: 0.2352 - val_accuracy: 0.9088\n",
      "Epoch 82/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2485 - accuracy: 0.8979 - val_loss: 0.2369 - val_accuracy: 0.9070\n",
      "Epoch 83/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2541 - accuracy: 0.8937 - val_loss: 0.2450 - val_accuracy: 0.9109\n",
      "Epoch 84/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2502 - accuracy: 0.9010 - val_loss: 0.2414 - val_accuracy: 0.9027\n",
      "Epoch 85/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2493 - accuracy: 0.8984 - val_loss: 0.2347 - val_accuracy: 0.9073\n",
      "Epoch 86/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2491 - accuracy: 0.9003 - val_loss: 0.2416 - val_accuracy: 0.9006\n",
      "Epoch 87/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2506 - accuracy: 0.8983 - val_loss: 0.2380 - val_accuracy: 0.9081\n",
      "Epoch 88/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2499 - accuracy: 0.9006 - val_loss: 0.2404 - val_accuracy: 0.9065\n",
      "Epoch 89/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2509 - accuracy: 0.8966 - val_loss: 0.2371 - val_accuracy: 0.9002\n",
      "Epoch 90/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2490 - accuracy: 0.9009 - val_loss: 0.2381 - val_accuracy: 0.8983\n",
      "Epoch 91/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2495 - accuracy: 0.8996 - val_loss: 0.2348 - val_accuracy: 0.9077\n",
      "Epoch 92/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2499 - accuracy: 0.8962 - val_loss: 0.2378 - val_accuracy: 0.9016\n",
      "Epoch 93/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2512 - accuracy: 0.8974 - val_loss: 0.2376 - val_accuracy: 0.9057\n",
      "Epoch 94/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2490 - accuracy: 0.9005 - val_loss: 0.2356 - val_accuracy: 0.9028\n",
      "Epoch 95/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2500 - accuracy: 0.8997 - val_loss: 0.2383 - val_accuracy: 0.9002\n",
      "Epoch 96/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2503 - accuracy: 0.8990 - val_loss: 0.2332 - val_accuracy: 0.9083\n",
      "Epoch 97/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2503 - accuracy: 0.8967 - val_loss: 0.2379 - val_accuracy: 0.9021\n",
      "Epoch 98/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2504 - accuracy: 0.8992 - val_loss: 0.2421 - val_accuracy: 0.9062\n",
      "Epoch 99/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2508 - accuracy: 0.8969 - val_loss: 0.2438 - val_accuracy: 0.9035\n",
      "Epoch 100/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2501 - accuracy: 0.8976 - val_loss: 0.2354 - val_accuracy: 0.9020\n",
      "Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "if( True ):\n",
    "    # Load the datasets\n",
    "    data1 = pd.read_csv('EEG_mouse_data_1.csv')\n",
    "    data2 = pd.read_csv('EEG_mouse_data_2.csv')\n",
    "\n",
    "    # Combine and preprocess the data\n",
    "    data_combined = pd.concat([data1, data2])\n",
    "    data_combined['state'] = data_combined['state'].replace({'n': 0, 'r': 0, 'w': 1})\n",
    "    X = data_combined.drop('state', axis=1)\n",
    "    y = data_combined['state']\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Feature selection with RFE\n",
    "    model = LogisticRegression(max_iter=10000)\n",
    "    rfe = RFE(estimator=model, n_features_to_select=25)\n",
    "    X_rfe = rfe.fit_transform(X_scaled, y)\n",
    "\n",
    "    y_keras = y.to_numpy()\n",
    "\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    history_list = []\n",
    "    trained_mlps = []\n",
    "\n",
    "    bestmodel = None\n",
    "    bestAccuracy = 0\n",
    "\n",
    "    for train_index, test_index in kf.split(X_rfe):\n",
    "\n",
    "        print(len(train_index))\n",
    "\n",
    "        mlp = create_model(X_rfe.shape[1])\n",
    "\n",
    "        # Les données doivent être divisées selon les indices définis par KFold\n",
    "        X_train_kf, X_test_kf = X_rfe[train_index], X_rfe[test_index]\n",
    "        y_train_kf, y_test_kf = y_keras[train_index], y_keras[test_index]\n",
    "\n",
    "        history = mlp.fit(\n",
    "            X_train_kf, y_train_kf,\n",
    "            validation_data=(X_test_kf, y_test_kf),\n",
    "            epochs=100, verbose=1\n",
    "        )\n",
    "\n",
    "        print(f\"Accuracy: {history.history['val_accuracy'][-1]:.2f}\")\n",
    "\n",
    "        history_list.append(history)\n",
    "        trained_mlps.append(mlp)\n",
    "\n",
    "        if history.history['val_accuracy'][-1] > bestAccuracy:\n",
    "            bestAccuracy = history.history['val_accuracy'][-1]\n",
    "            bestmodel = mlp\n",
    "else :\n",
    "\n",
    "    # Get the highest float value from the filenames\n",
    "    highest_float = float('-inf')\n",
    "    files = os.listdir('.')\n",
    "\n",
    "    model_file = [fichier for fichier in os.listdir('.') if fichier.startswith('m_')]\n",
    "    model_file_float = [fichier[2:] for fichier in model_file]\n",
    "    for file in model_file_float:\n",
    "        float_value = float(file)\n",
    "        if float_value > highest_float:\n",
    "            highest_float = float_value\n",
    "\n",
    "    # Load the model from the highest float filename\n",
    "    model_filename = 'm_' + str(highest_float)\n",
    "    model = keras.models.load_model(model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: m_0.9019895792007446/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: m_0.9019895792007446/assets\n"
     ]
    }
   ],
   "source": [
    "bestmodel.save(f'm_{bestAccuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
