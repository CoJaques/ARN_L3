{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Folder = \"pw3_data\"\n",
    "Files = [\"EEG_mouse_data_1.csv\", \"EEG_mouse_data_2.csv\"]\n",
    "\n",
    "# Lecture des données\n",
    "datas = []\n",
    "for file in Files:\n",
    "    datas.append(pd.read_csv(Folder + \"/\" + file))\n",
    "\n",
    "# Concaténation des données\n",
    "mouse1_eeg = pd.concat(datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sélection des features et normalisation des données.\n",
    "\n",
    "J'ai choisi ici de sélectionner des features de manière à ce qu'elles soient les plus pertinentes possibles pour la prédiction de la variable cible. Pour cela, j'ai utilisé la méthode de sélection de features de type \"wrapper\" appelée \"Recursive Feature Elimination\" (RFE) qui consiste à éliminer les features une à une en fonction de leur importance pour la prédiction de la variable cible. J'ai utilisé pour cela un modèle de régression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   amplitude_around_1_Hertz  amplitude_around_5_Hertz  \\\n",
      "0                 -0.209955                  0.818127   \n",
      "1                 -0.183434                  0.740384   \n",
      "2                 -0.143389                  0.036759   \n",
      "3                 -0.443261                 -0.510886   \n",
      "4                 -0.187587                  0.570556   \n",
      "\n",
      "   amplitude_around_9_Hertz  amplitude_around_13_Hertz  \\\n",
      "0                  0.709286                  -0.133015   \n",
      "1                  0.099354                  -0.289620   \n",
      "2                 -0.457418                  -0.426393   \n",
      "3                 -0.465943                   0.431755   \n",
      "4                  0.829106                   0.528520   \n",
      "\n",
      "   amplitude_around_17_Hertz  amplitude_around_21_Hertz  \\\n",
      "0                  -0.356923                   0.046292   \n",
      "1                   0.893280                   1.456953   \n",
      "2                   1.615055                  -0.280723   \n",
      "3                  -0.464970                  -0.643038   \n",
      "4                   1.349163                   1.142469   \n",
      "\n",
      "   amplitude_around_26_Hertz  amplitude_around_30_Hertz  \\\n",
      "0                   0.027963                  -0.737488   \n",
      "1                  -0.119493                   1.276719   \n",
      "2                  -0.611553                  -0.292198   \n",
      "3                   0.181318                  -1.142626   \n",
      "4                   0.722038                   0.153974   \n",
      "\n",
      "   amplitude_around_34_Hertz  amplitude_around_38_Hertz  ...  \\\n",
      "0                   3.588603                  -0.225196  ...   \n",
      "1                  -0.988009                  -0.760906  ...   \n",
      "2                  -1.181536                  -1.174003  ...   \n",
      "3                   1.131791                  -0.970308  ...   \n",
      "4                   0.401841                  -0.180036  ...   \n",
      "\n",
      "   amplitude_around_63_Hertz  amplitude_around_67_Hertz  \\\n",
      "0                  -0.614165                  -0.011298   \n",
      "1                  -0.979405                   2.034203   \n",
      "2                  -0.250777                  -0.914553   \n",
      "3                  -1.126762                  -0.447982   \n",
      "4                  -0.251609                  -0.955284   \n",
      "\n",
      "   amplitude_around_71_Hertz  amplitude_around_76_Hertz  \\\n",
      "0                   0.579361                  -0.757191   \n",
      "1                  -0.767949                  -0.418021   \n",
      "2                  -1.006095                  -0.916607   \n",
      "3                  -0.436532                  -0.180410   \n",
      "4                  -0.514999                   0.472545   \n",
      "\n",
      "   amplitude_around_80_Hertz  amplitude_around_84_Hertz  \\\n",
      "0                  -0.695886                   0.208107   \n",
      "1                   0.547928                  -1.220401   \n",
      "2                  -1.123806                  -0.723460   \n",
      "3                  -0.818964                  -1.062777   \n",
      "4                  -0.642358                  -0.434973   \n",
      "\n",
      "   amplitude_around_88_Hertz  amplitude_around_92_Hertz  \\\n",
      "0                   0.613812                  -0.731088   \n",
      "1                  -0.542838                  -0.862596   \n",
      "2                  -0.647694                  -0.518808   \n",
      "3                  -1.173185                   0.362702   \n",
      "4                  -0.455470                  -0.874739   \n",
      "\n",
      "   amplitude_around_96_Hertz  amplitude_around_101_Hertz  \n",
      "0                  -0.026148                    1.334097  \n",
      "1                  -0.747605                    1.290267  \n",
      "2                   0.067799                    2.124263  \n",
      "3                  -0.757451                   -0.415788  \n",
      "4                  -0.631579                   -1.009175  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Exemple de sélection de 25 caractéristiques réparties uniformément\n",
    "selected_features = np.linspace(1, 101, 25, dtype=int)\n",
    "selected_features = [f'amplitude_around_{i}_Hertz' for i in selected_features]\n",
    "\n",
    "# Extraction des données correspondant aux caractéristiques sélectionnées\n",
    "data_selected = mouse1_eeg[selected_features]\n",
    "\n",
    "# Normalisation des données avec Z-score\n",
    "scaler = StandardScaler()\n",
    "data_normalized = scaler.fit_transform(data_selected)\n",
    "\n",
    "# Conversion en DataFrame pour une utilisation ultérieure\n",
    "data_normalized_df = pd.DataFrame(data_normalized, columns=selected_features)\n",
    "\n",
    "# Affichage des 5 premières lignes du DataFrame\n",
    "print(data_normalized_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim):\n",
    "    mlp = keras.Sequential([\n",
    "        layers.Dense(2, activation=\"tanh\", input_shape=(input_dim,)),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ])\n",
    "\n",
    "    mlp.compile(\n",
    "        optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.99),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29190/540334327.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data_combined['state'] = data_combined['state'].replace({'n': 0, 'r': 0, 'w': 1})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27242\n",
      "Epoch 1/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2795 - accuracy: 0.8951 - val_loss: 0.2664 - val_accuracy: 0.9036\n",
      "Epoch 2/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2595 - accuracy: 0.8988 - val_loss: 0.2669 - val_accuracy: 0.9004\n",
      "Epoch 3/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2547 - accuracy: 0.9008 - val_loss: 0.2548 - val_accuracy: 0.8975\n",
      "Epoch 4/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2482 - accuracy: 0.9009 - val_loss: 0.2530 - val_accuracy: 0.8988\n",
      "Epoch 5/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2479 - accuracy: 0.8970 - val_loss: 0.2541 - val_accuracy: 0.8850\n",
      "Epoch 6/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2436 - accuracy: 0.8998 - val_loss: 0.2494 - val_accuracy: 0.8935\n",
      "Epoch 7/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2450 - accuracy: 0.8974 - val_loss: 0.2539 - val_accuracy: 0.8895\n",
      "Epoch 8/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2455 - accuracy: 0.8978 - val_loss: 0.2495 - val_accuracy: 0.9051\n",
      "Epoch 9/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.8991 - val_loss: 0.2522 - val_accuracy: 0.9027\n",
      "Epoch 10/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2442 - accuracy: 0.9002 - val_loss: 0.2518 - val_accuracy: 0.8903\n",
      "Epoch 11/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2448 - accuracy: 0.9030 - val_loss: 0.2503 - val_accuracy: 0.8999\n",
      "Epoch 12/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2458 - accuracy: 0.8996 - val_loss: 0.2496 - val_accuracy: 0.8904\n",
      "Epoch 13/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2461 - accuracy: 0.8978 - val_loss: 0.2472 - val_accuracy: 0.9007\n",
      "Epoch 14/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2446 - accuracy: 0.9000 - val_loss: 0.2509 - val_accuracy: 0.9022\n",
      "Epoch 15/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.8979 - val_loss: 0.2494 - val_accuracy: 0.8964\n",
      "Epoch 16/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.8991 - val_loss: 0.2644 - val_accuracy: 0.8888\n",
      "Epoch 17/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2442 - accuracy: 0.9007 - val_loss: 0.2568 - val_accuracy: 0.8973\n",
      "Epoch 18/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2447 - accuracy: 0.8977 - val_loss: 0.2509 - val_accuracy: 0.8995\n",
      "Epoch 19/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2443 - accuracy: 0.8987 - val_loss: 0.2544 - val_accuracy: 0.8960\n",
      "Epoch 20/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.8973 - val_loss: 0.2550 - val_accuracy: 0.8912\n",
      "Epoch 21/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2449 - accuracy: 0.8984 - val_loss: 0.2542 - val_accuracy: 0.9011\n",
      "Epoch 22/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2443 - accuracy: 0.9006 - val_loss: 0.2525 - val_accuracy: 0.9014\n",
      "Epoch 23/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.8998 - val_loss: 0.2505 - val_accuracy: 0.8985\n",
      "Epoch 24/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.9008 - val_loss: 0.2482 - val_accuracy: 0.8983\n",
      "Epoch 25/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2448 - accuracy: 0.8996 - val_loss: 0.2482 - val_accuracy: 0.9012\n",
      "Epoch 26/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.9005 - val_loss: 0.2475 - val_accuracy: 0.9011\n",
      "Epoch 27/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2437 - accuracy: 0.9001 - val_loss: 0.2522 - val_accuracy: 0.9048\n",
      "Epoch 28/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2444 - accuracy: 0.9010 - val_loss: 0.2540 - val_accuracy: 0.9026\n",
      "Epoch 29/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2447 - accuracy: 0.8967 - val_loss: 0.2497 - val_accuracy: 0.9046\n",
      "Epoch 30/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2443 - accuracy: 0.8996 - val_loss: 0.2492 - val_accuracy: 0.8944\n",
      "Epoch 31/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2434 - accuracy: 0.9001 - val_loss: 0.2538 - val_accuracy: 0.8870\n",
      "Epoch 32/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2469 - accuracy: 0.8968 - val_loss: 0.2465 - val_accuracy: 0.9035\n",
      "Epoch 33/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2463 - accuracy: 0.8984 - val_loss: 0.2529 - val_accuracy: 0.8985\n",
      "Epoch 34/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2460 - accuracy: 0.8985 - val_loss: 0.2526 - val_accuracy: 0.8967\n",
      "Epoch 35/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.8992 - val_loss: 0.2512 - val_accuracy: 0.8941\n",
      "Epoch 36/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2461 - accuracy: 0.8973 - val_loss: 0.2516 - val_accuracy: 0.8971\n",
      "Epoch 37/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2458 - accuracy: 0.8963 - val_loss: 0.2472 - val_accuracy: 0.9020\n",
      "Epoch 38/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2448 - accuracy: 0.8967 - val_loss: 0.2478 - val_accuracy: 0.9076\n",
      "Epoch 39/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2458 - accuracy: 0.8982 - val_loss: 0.2528 - val_accuracy: 0.8983\n",
      "Epoch 40/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2446 - accuracy: 0.8975 - val_loss: 0.2493 - val_accuracy: 0.9015\n",
      "Epoch 41/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2442 - accuracy: 0.9005 - val_loss: 0.2527 - val_accuracy: 0.8994\n",
      "Epoch 42/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2466 - accuracy: 0.8970 - val_loss: 0.2507 - val_accuracy: 0.8908\n",
      "Epoch 43/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2461 - accuracy: 0.8956 - val_loss: 0.2516 - val_accuracy: 0.8966\n",
      "Epoch 44/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2454 - accuracy: 0.9004 - val_loss: 0.2512 - val_accuracy: 0.8965\n",
      "Epoch 45/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2446 - accuracy: 0.8986 - val_loss: 0.2474 - val_accuracy: 0.9016\n",
      "Epoch 46/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2456 - accuracy: 0.8998 - val_loss: 0.2495 - val_accuracy: 0.8944\n",
      "Epoch 47/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2437 - accuracy: 0.9000 - val_loss: 0.2495 - val_accuracy: 0.8973\n",
      "Epoch 48/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.9021 - val_loss: 0.2480 - val_accuracy: 0.9057\n",
      "Epoch 49/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2435 - accuracy: 0.9000 - val_loss: 0.2503 - val_accuracy: 0.8956\n",
      "Epoch 50/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2420 - accuracy: 0.9006 - val_loss: 0.2509 - val_accuracy: 0.8977\n",
      "Epoch 51/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2461 - accuracy: 0.8971 - val_loss: 0.2528 - val_accuracy: 0.8942\n",
      "Epoch 52/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2458 - accuracy: 0.9001 - val_loss: 0.2452 - val_accuracy: 0.9053\n",
      "Epoch 53/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2446 - accuracy: 0.9011 - val_loss: 0.2488 - val_accuracy: 0.8883\n",
      "Epoch 54/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2448 - accuracy: 0.8985 - val_loss: 0.2512 - val_accuracy: 0.8995\n",
      "Epoch 55/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.8992 - val_loss: 0.2480 - val_accuracy: 0.8988\n",
      "Epoch 56/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2436 - accuracy: 0.8988 - val_loss: 0.2498 - val_accuracy: 0.9010\n",
      "Epoch 57/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2446 - accuracy: 0.8971 - val_loss: 0.2517 - val_accuracy: 0.8933\n",
      "Epoch 58/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2445 - accuracy: 0.8981 - val_loss: 0.2495 - val_accuracy: 0.8959\n",
      "Epoch 59/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2448 - accuracy: 0.8993 - val_loss: 0.2497 - val_accuracy: 0.9052\n",
      "Epoch 60/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2455 - accuracy: 0.8988 - val_loss: 0.2467 - val_accuracy: 0.8977\n",
      "Epoch 61/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2436 - accuracy: 0.8996 - val_loss: 0.2491 - val_accuracy: 0.9032\n",
      "Epoch 62/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2435 - accuracy: 0.9007 - val_loss: 0.2505 - val_accuracy: 0.9016\n",
      "Epoch 63/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2423 - accuracy: 0.9004 - val_loss: 0.2471 - val_accuracy: 0.9082\n",
      "Epoch 64/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2449 - accuracy: 0.8994 - val_loss: 0.2484 - val_accuracy: 0.9047\n",
      "Epoch 65/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2439 - accuracy: 0.9003 - val_loss: 0.2531 - val_accuracy: 0.8935\n",
      "Epoch 66/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2450 - accuracy: 0.8976 - val_loss: 0.2482 - val_accuracy: 0.8994\n",
      "Epoch 67/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2448 - accuracy: 0.8977 - val_loss: 0.2547 - val_accuracy: 0.8894\n",
      "Epoch 68/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2450 - accuracy: 0.8959 - val_loss: 0.2499 - val_accuracy: 0.8952\n",
      "Epoch 69/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2434 - accuracy: 0.8990 - val_loss: 0.2548 - val_accuracy: 0.8883\n",
      "Epoch 70/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2441 - accuracy: 0.8984 - val_loss: 0.2487 - val_accuracy: 0.8985\n",
      "Epoch 71/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.8978 - val_loss: 0.2516 - val_accuracy: 0.8919\n",
      "Epoch 72/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2434 - accuracy: 0.9002 - val_loss: 0.2495 - val_accuracy: 0.9068\n",
      "Epoch 73/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.8985 - val_loss: 0.2509 - val_accuracy: 0.9052\n",
      "Epoch 74/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.9002 - val_loss: 0.2553 - val_accuracy: 0.8899\n",
      "Epoch 75/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2450 - accuracy: 0.8996 - val_loss: 0.2517 - val_accuracy: 0.8948\n",
      "Epoch 76/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2441 - accuracy: 0.8995 - val_loss: 0.2491 - val_accuracy: 0.9045\n",
      "Epoch 77/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2463 - accuracy: 0.9010 - val_loss: 0.2556 - val_accuracy: 0.8944\n",
      "Epoch 78/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2461 - accuracy: 0.8999 - val_loss: 0.2496 - val_accuracy: 0.8942\n",
      "Epoch 79/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2457 - accuracy: 0.8970 - val_loss: 0.2555 - val_accuracy: 0.8876\n",
      "Epoch 80/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2444 - accuracy: 0.9000 - val_loss: 0.2550 - val_accuracy: 0.8958\n",
      "Epoch 81/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2454 - accuracy: 0.8960 - val_loss: 0.2483 - val_accuracy: 0.9007\n",
      "Epoch 82/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2448 - accuracy: 0.8985 - val_loss: 0.2493 - val_accuracy: 0.8945\n",
      "Epoch 83/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2445 - accuracy: 0.9005 - val_loss: 0.2505 - val_accuracy: 0.9029\n",
      "Epoch 84/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2445 - accuracy: 0.9009 - val_loss: 0.2468 - val_accuracy: 0.9027\n",
      "Epoch 85/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2462 - accuracy: 0.8959 - val_loss: 0.2525 - val_accuracy: 0.8899\n",
      "Epoch 86/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2465 - accuracy: 0.8990 - val_loss: 0.2496 - val_accuracy: 0.9077\n",
      "Epoch 87/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2452 - accuracy: 0.8994 - val_loss: 0.2535 - val_accuracy: 0.8931\n",
      "Epoch 88/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.9006 - val_loss: 0.2525 - val_accuracy: 0.8977\n",
      "Epoch 89/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2437 - accuracy: 0.8999 - val_loss: 0.2505 - val_accuracy: 0.8960\n",
      "Epoch 90/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.8985 - val_loss: 0.2506 - val_accuracy: 0.8993\n",
      "Epoch 91/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2443 - accuracy: 0.8994 - val_loss: 0.2477 - val_accuracy: 0.9024\n",
      "Epoch 92/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2439 - accuracy: 0.9005 - val_loss: 0.2472 - val_accuracy: 0.9013\n",
      "Epoch 93/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2464 - accuracy: 0.8960 - val_loss: 0.2540 - val_accuracy: 0.8998\n",
      "Epoch 94/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2489 - accuracy: 0.8968 - val_loss: 0.2497 - val_accuracy: 0.9022\n",
      "Epoch 95/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2444 - accuracy: 0.8982 - val_loss: 0.2489 - val_accuracy: 0.8997\n",
      "Epoch 96/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2442 - accuracy: 0.9017 - val_loss: 0.2483 - val_accuracy: 0.8971\n",
      "Epoch 97/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2464 - accuracy: 0.8969 - val_loss: 0.2512 - val_accuracy: 0.8943\n",
      "Epoch 98/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2436 - accuracy: 0.8984 - val_loss: 0.2517 - val_accuracy: 0.8990\n",
      "Epoch 99/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2452 - accuracy: 0.8996 - val_loss: 0.2507 - val_accuracy: 0.8938\n",
      "Epoch 100/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2445 - accuracy: 0.9003 - val_loss: 0.2488 - val_accuracy: 0.8981\n",
      "Accuracy: 0.90\n",
      "27242\n",
      "Epoch 1/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2854 - accuracy: 0.8975 - val_loss: 0.2727 - val_accuracy: 0.8993\n",
      "Epoch 2/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2601 - accuracy: 0.9031 - val_loss: 0.2671 - val_accuracy: 0.9007\n",
      "Epoch 3/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2579 - accuracy: 0.9039 - val_loss: 0.2661 - val_accuracy: 0.9004\n",
      "Epoch 4/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2579 - accuracy: 0.9015 - val_loss: 0.2690 - val_accuracy: 0.8811\n",
      "Epoch 5/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2547 - accuracy: 0.9033 - val_loss: 0.2659 - val_accuracy: 0.9006\n",
      "Epoch 6/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2555 - accuracy: 0.9032 - val_loss: 0.2651 - val_accuracy: 0.8986\n",
      "Epoch 7/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2541 - accuracy: 0.9036 - val_loss: 0.2622 - val_accuracy: 0.9006\n",
      "Epoch 8/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2541 - accuracy: 0.9022 - val_loss: 0.2628 - val_accuracy: 0.9021\n",
      "Epoch 9/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2551 - accuracy: 0.9009 - val_loss: 0.2663 - val_accuracy: 0.9023\n",
      "Epoch 10/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2546 - accuracy: 0.9034 - val_loss: 0.2636 - val_accuracy: 0.9027\n",
      "Epoch 11/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2544 - accuracy: 0.9038 - val_loss: 0.2654 - val_accuracy: 0.9011\n",
      "Epoch 12/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2547 - accuracy: 0.9061 - val_loss: 0.2631 - val_accuracy: 0.9032\n",
      "Epoch 13/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2543 - accuracy: 0.9031 - val_loss: 0.2625 - val_accuracy: 0.9021\n",
      "Epoch 14/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2515 - accuracy: 0.9036 - val_loss: 0.2521 - val_accuracy: 0.9024\n",
      "Epoch 15/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2464 - accuracy: 0.9002 - val_loss: 0.2554 - val_accuracy: 0.8980\n",
      "Epoch 16/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2450 - accuracy: 0.9018 - val_loss: 0.2494 - val_accuracy: 0.8966\n",
      "Epoch 17/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2444 - accuracy: 0.9019 - val_loss: 0.2511 - val_accuracy: 0.8990\n",
      "Epoch 18/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2448 - accuracy: 0.8997 - val_loss: 0.2505 - val_accuracy: 0.8973\n",
      "Epoch 19/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.9010 - val_loss: 0.2497 - val_accuracy: 0.8991\n",
      "Epoch 20/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2447 - accuracy: 0.9003 - val_loss: 0.2532 - val_accuracy: 0.9025\n",
      "Epoch 21/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2431 - accuracy: 0.9007 - val_loss: 0.2518 - val_accuracy: 0.8974\n",
      "Epoch 22/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2449 - accuracy: 0.9004 - val_loss: 0.2586 - val_accuracy: 0.8793\n",
      "Epoch 23/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2441 - accuracy: 0.9014 - val_loss: 0.2499 - val_accuracy: 0.8942\n",
      "Epoch 24/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2436 - accuracy: 0.9003 - val_loss: 0.2558 - val_accuracy: 0.8892\n",
      "Epoch 25/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2437 - accuracy: 0.8993 - val_loss: 0.2471 - val_accuracy: 0.8964\n",
      "Epoch 26/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2460 - accuracy: 0.8993 - val_loss: 0.2484 - val_accuracy: 0.9026\n",
      "Epoch 27/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2462 - accuracy: 0.8998 - val_loss: 0.2480 - val_accuracy: 0.8948\n",
      "Epoch 28/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.9016 - val_loss: 0.2516 - val_accuracy: 0.8974\n",
      "Epoch 29/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.9000 - val_loss: 0.2522 - val_accuracy: 0.8949\n",
      "Epoch 30/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2433 - accuracy: 0.9015 - val_loss: 0.2500 - val_accuracy: 0.8944\n",
      "Epoch 31/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2424 - accuracy: 0.9015 - val_loss: 0.2506 - val_accuracy: 0.8971\n",
      "Epoch 32/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2443 - accuracy: 0.9028 - val_loss: 0.2495 - val_accuracy: 0.8949\n",
      "Epoch 33/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.9009 - val_loss: 0.2508 - val_accuracy: 0.8976\n",
      "Epoch 34/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2441 - accuracy: 0.9013 - val_loss: 0.2498 - val_accuracy: 0.9013\n",
      "Epoch 35/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2441 - accuracy: 0.9011 - val_loss: 0.2480 - val_accuracy: 0.9026\n",
      "Epoch 36/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2436 - accuracy: 0.8999 - val_loss: 0.2479 - val_accuracy: 0.8983\n",
      "Epoch 37/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2443 - accuracy: 0.9012 - val_loss: 0.2504 - val_accuracy: 0.9004\n",
      "Epoch 38/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2433 - accuracy: 0.9034 - val_loss: 0.2544 - val_accuracy: 0.8944\n",
      "Epoch 39/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2463 - accuracy: 0.9005 - val_loss: 0.2507 - val_accuracy: 0.8944\n",
      "Epoch 40/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2429 - accuracy: 0.9019 - val_loss: 0.2519 - val_accuracy: 0.8930\n",
      "Epoch 41/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.9022 - val_loss: 0.2543 - val_accuracy: 0.8882\n",
      "Epoch 42/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2450 - accuracy: 0.9000 - val_loss: 0.2499 - val_accuracy: 0.8969\n",
      "Epoch 43/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.9029 - val_loss: 0.2515 - val_accuracy: 0.8989\n",
      "Epoch 44/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2447 - accuracy: 0.9007 - val_loss: 0.2530 - val_accuracy: 0.8999\n",
      "Epoch 45/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2456 - accuracy: 0.8988 - val_loss: 0.2547 - val_accuracy: 0.9043\n",
      "Epoch 46/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2449 - accuracy: 0.9014 - val_loss: 0.2509 - val_accuracy: 0.8930\n",
      "Epoch 47/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2437 - accuracy: 0.9020 - val_loss: 0.2514 - val_accuracy: 0.8963\n",
      "Epoch 48/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2428 - accuracy: 0.9021 - val_loss: 0.2612 - val_accuracy: 0.8757\n",
      "Epoch 49/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2467 - accuracy: 0.8985 - val_loss: 0.2523 - val_accuracy: 0.8913\n",
      "Epoch 50/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2428 - accuracy: 0.9030 - val_loss: 0.2635 - val_accuracy: 0.8881\n",
      "Epoch 51/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2436 - accuracy: 0.9033 - val_loss: 0.2493 - val_accuracy: 0.8986\n",
      "Epoch 52/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2444 - accuracy: 0.9001 - val_loss: 0.2550 - val_accuracy: 0.8952\n",
      "Epoch 53/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.9006 - val_loss: 0.2473 - val_accuracy: 0.8991\n",
      "Epoch 54/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.9028 - val_loss: 0.2485 - val_accuracy: 0.8996\n",
      "Epoch 55/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2434 - accuracy: 0.9000 - val_loss: 0.2492 - val_accuracy: 0.8954\n",
      "Epoch 56/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2433 - accuracy: 0.9011 - val_loss: 0.2507 - val_accuracy: 0.8942\n",
      "Epoch 57/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.9033 - val_loss: 0.2457 - val_accuracy: 0.8996\n",
      "Epoch 58/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2435 - accuracy: 0.9017 - val_loss: 0.2540 - val_accuracy: 0.8982\n",
      "Epoch 59/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2436 - accuracy: 0.9002 - val_loss: 0.2499 - val_accuracy: 0.8971\n",
      "Epoch 60/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2437 - accuracy: 0.9007 - val_loss: 0.2485 - val_accuracy: 0.8978\n",
      "Epoch 61/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.9003 - val_loss: 0.2519 - val_accuracy: 0.8902\n",
      "Epoch 62/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2433 - accuracy: 0.9028 - val_loss: 0.2502 - val_accuracy: 0.8980\n",
      "Epoch 63/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.9021 - val_loss: 0.2472 - val_accuracy: 0.9046\n",
      "Epoch 64/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.9015 - val_loss: 0.2527 - val_accuracy: 0.8940\n",
      "Epoch 65/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2429 - accuracy: 0.9028 - val_loss: 0.2485 - val_accuracy: 0.8967\n",
      "Epoch 66/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2448 - accuracy: 0.9029 - val_loss: 0.2498 - val_accuracy: 0.9005\n",
      "Epoch 67/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.8984 - val_loss: 0.2530 - val_accuracy: 0.8941\n",
      "Epoch 68/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2434 - accuracy: 0.9020 - val_loss: 0.2516 - val_accuracy: 0.8892\n",
      "Epoch 69/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2464 - accuracy: 0.8990 - val_loss: 0.2508 - val_accuracy: 0.9004\n",
      "Epoch 70/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2429 - accuracy: 0.9036 - val_loss: 0.2495 - val_accuracy: 0.8971\n",
      "Epoch 71/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2449 - accuracy: 0.9025 - val_loss: 0.2494 - val_accuracy: 0.8949\n",
      "Epoch 72/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2445 - accuracy: 0.9018 - val_loss: 0.2503 - val_accuracy: 0.8964\n",
      "Epoch 73/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2442 - accuracy: 0.9014 - val_loss: 0.2505 - val_accuracy: 0.9049\n",
      "Epoch 74/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2444 - accuracy: 0.9008 - val_loss: 0.2501 - val_accuracy: 0.8971\n",
      "Epoch 75/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2437 - accuracy: 0.9021 - val_loss: 0.2520 - val_accuracy: 0.8914\n",
      "Epoch 76/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2442 - accuracy: 0.9029 - val_loss: 0.2511 - val_accuracy: 0.8948\n",
      "Epoch 77/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2439 - accuracy: 0.9016 - val_loss: 0.2520 - val_accuracy: 0.8911\n",
      "Epoch 78/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2436 - accuracy: 0.9007 - val_loss: 0.2544 - val_accuracy: 0.8960\n",
      "Epoch 79/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2426 - accuracy: 0.9047 - val_loss: 0.2580 - val_accuracy: 0.9002\n",
      "Epoch 80/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2445 - accuracy: 0.9020 - val_loss: 0.2534 - val_accuracy: 0.8895\n",
      "Epoch 81/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2445 - accuracy: 0.8998 - val_loss: 0.2512 - val_accuracy: 0.9032\n",
      "Epoch 82/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2450 - accuracy: 0.9018 - val_loss: 0.2519 - val_accuracy: 0.8939\n",
      "Epoch 83/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2425 - accuracy: 0.9021 - val_loss: 0.2497 - val_accuracy: 0.8977\n",
      "Epoch 84/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.8984 - val_loss: 0.2544 - val_accuracy: 0.8943\n",
      "Epoch 85/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.9020 - val_loss: 0.2513 - val_accuracy: 0.8980\n",
      "Epoch 86/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2458 - accuracy: 0.9003 - val_loss: 0.2552 - val_accuracy: 0.8852\n",
      "Epoch 87/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2447 - accuracy: 0.8999 - val_loss: 0.2535 - val_accuracy: 0.8919\n",
      "Epoch 88/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2444 - accuracy: 0.9027 - val_loss: 0.2518 - val_accuracy: 0.8984\n",
      "Epoch 89/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2443 - accuracy: 0.9008 - val_loss: 0.2484 - val_accuracy: 0.8950\n",
      "Epoch 90/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2437 - accuracy: 0.9012 - val_loss: 0.2475 - val_accuracy: 0.8930\n",
      "Epoch 91/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.9014 - val_loss: 0.2543 - val_accuracy: 0.8969\n",
      "Epoch 92/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2465 - accuracy: 0.8998 - val_loss: 0.2518 - val_accuracy: 0.8883\n",
      "Epoch 93/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2434 - accuracy: 0.9025 - val_loss: 0.2502 - val_accuracy: 0.8992\n",
      "Epoch 94/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2435 - accuracy: 0.9023 - val_loss: 0.2531 - val_accuracy: 0.8931\n",
      "Epoch 95/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2445 - accuracy: 0.9031 - val_loss: 0.2548 - val_accuracy: 0.9010\n",
      "Epoch 96/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2430 - accuracy: 0.9016 - val_loss: 0.2507 - val_accuracy: 0.9010\n",
      "Epoch 97/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2444 - accuracy: 0.9011 - val_loss: 0.2485 - val_accuracy: 0.9027\n",
      "Epoch 98/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2446 - accuracy: 0.9022 - val_loss: 0.2504 - val_accuracy: 0.9010\n",
      "Epoch 99/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2429 - accuracy: 0.8998 - val_loss: 0.2516 - val_accuracy: 0.8936\n",
      "Epoch 100/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2460 - accuracy: 0.8982 - val_loss: 0.2505 - val_accuracy: 0.8988\n",
      "Accuracy: 0.90\n",
      "27242\n",
      "Epoch 1/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2893 - accuracy: 0.8892 - val_loss: 0.2520 - val_accuracy: 0.9059\n",
      "Epoch 2/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2569 - accuracy: 0.9033 - val_loss: 0.2452 - val_accuracy: 0.9048\n",
      "Epoch 3/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2556 - accuracy: 0.8982 - val_loss: 0.2377 - val_accuracy: 0.9027\n",
      "Epoch 4/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2521 - accuracy: 0.8964 - val_loss: 0.2376 - val_accuracy: 0.8985\n",
      "Epoch 5/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2525 - accuracy: 0.8973 - val_loss: 0.2381 - val_accuracy: 0.8976\n",
      "Epoch 6/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2494 - accuracy: 0.8975 - val_loss: 0.2414 - val_accuracy: 0.9004\n",
      "Epoch 7/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2515 - accuracy: 0.8947 - val_loss: 0.2442 - val_accuracy: 0.8925\n",
      "Epoch 8/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2514 - accuracy: 0.8956 - val_loss: 0.2353 - val_accuracy: 0.9036\n",
      "Epoch 9/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2503 - accuracy: 0.8972 - val_loss: 0.2412 - val_accuracy: 0.8992\n",
      "Epoch 10/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2503 - accuracy: 0.8989 - val_loss: 0.2375 - val_accuracy: 0.9060\n",
      "Epoch 11/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2526 - accuracy: 0.8951 - val_loss: 0.2383 - val_accuracy: 0.9013\n",
      "Epoch 12/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2528 - accuracy: 0.8941 - val_loss: 0.2426 - val_accuracy: 0.8903\n",
      "Epoch 13/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2491 - accuracy: 0.8971 - val_loss: 0.2360 - val_accuracy: 0.9080\n",
      "Epoch 14/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2482 - accuracy: 0.8992 - val_loss: 0.2421 - val_accuracy: 0.9068\n",
      "Epoch 15/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2501 - accuracy: 0.8965 - val_loss: 0.2402 - val_accuracy: 0.9096\n",
      "Epoch 16/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2508 - accuracy: 0.8984 - val_loss: 0.2370 - val_accuracy: 0.9112\n",
      "Epoch 17/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2514 - accuracy: 0.8969 - val_loss: 0.2319 - val_accuracy: 0.9087\n",
      "Epoch 18/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2513 - accuracy: 0.8982 - val_loss: 0.2390 - val_accuracy: 0.8969\n",
      "Epoch 19/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2505 - accuracy: 0.8983 - val_loss: 0.2391 - val_accuracy: 0.8996\n",
      "Epoch 20/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2513 - accuracy: 0.8976 - val_loss: 0.2342 - val_accuracy: 0.9058\n",
      "Epoch 21/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2490 - accuracy: 0.9006 - val_loss: 0.2387 - val_accuracy: 0.9007\n",
      "Epoch 22/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2504 - accuracy: 0.8998 - val_loss: 0.2403 - val_accuracy: 0.8938\n",
      "Epoch 23/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2494 - accuracy: 0.8982 - val_loss: 0.2406 - val_accuracy: 0.8989\n",
      "Epoch 24/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2515 - accuracy: 0.8962 - val_loss: 0.2392 - val_accuracy: 0.9095\n",
      "Epoch 25/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2492 - accuracy: 0.9002 - val_loss: 0.2364 - val_accuracy: 0.9031\n",
      "Epoch 26/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2506 - accuracy: 0.8970 - val_loss: 0.2357 - val_accuracy: 0.9027\n",
      "Epoch 27/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2513 - accuracy: 0.8980 - val_loss: 0.2482 - val_accuracy: 0.8905\n",
      "Epoch 28/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2508 - accuracy: 0.8964 - val_loss: 0.2371 - val_accuracy: 0.9042\n",
      "Epoch 29/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2489 - accuracy: 0.8980 - val_loss: 0.2430 - val_accuracy: 0.8966\n",
      "Epoch 30/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2529 - accuracy: 0.8927 - val_loss: 0.2368 - val_accuracy: 0.9089\n",
      "Epoch 31/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2511 - accuracy: 0.8960 - val_loss: 0.2357 - val_accuracy: 0.9090\n",
      "Epoch 32/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2525 - accuracy: 0.8989 - val_loss: 0.2378 - val_accuracy: 0.9089\n",
      "Epoch 33/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2493 - accuracy: 0.8996 - val_loss: 0.2423 - val_accuracy: 0.8960\n",
      "Epoch 34/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2522 - accuracy: 0.8978 - val_loss: 0.2374 - val_accuracy: 0.9046\n",
      "Epoch 35/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2497 - accuracy: 0.8979 - val_loss: 0.2408 - val_accuracy: 0.8996\n",
      "Epoch 36/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2514 - accuracy: 0.8956 - val_loss: 0.2422 - val_accuracy: 0.8999\n",
      "Epoch 37/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2542 - accuracy: 0.8939 - val_loss: 0.2417 - val_accuracy: 0.9060\n",
      "Epoch 38/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2515 - accuracy: 0.8969 - val_loss: 0.2363 - val_accuracy: 0.9052\n",
      "Epoch 39/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2513 - accuracy: 0.8978 - val_loss: 0.2374 - val_accuracy: 0.9063\n",
      "Epoch 40/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2499 - accuracy: 0.8983 - val_loss: 0.2362 - val_accuracy: 0.9094\n",
      "Epoch 41/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2497 - accuracy: 0.8973 - val_loss: 0.2382 - val_accuracy: 0.8985\n",
      "Epoch 42/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2510 - accuracy: 0.8998 - val_loss: 0.2412 - val_accuracy: 0.9036\n",
      "Epoch 43/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2505 - accuracy: 0.8998 - val_loss: 0.2367 - val_accuracy: 0.9054\n",
      "Epoch 44/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2518 - accuracy: 0.8963 - val_loss: 0.2386 - val_accuracy: 0.9056\n",
      "Epoch 45/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2505 - accuracy: 0.8982 - val_loss: 0.2365 - val_accuracy: 0.9050\n",
      "Epoch 46/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2514 - accuracy: 0.8963 - val_loss: 0.2376 - val_accuracy: 0.9082\n",
      "Epoch 47/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2506 - accuracy: 0.8991 - val_loss: 0.2356 - val_accuracy: 0.9101\n",
      "Epoch 48/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2512 - accuracy: 0.9000 - val_loss: 0.2404 - val_accuracy: 0.8952\n",
      "Epoch 49/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2506 - accuracy: 0.8989 - val_loss: 0.2369 - val_accuracy: 0.9085\n",
      "Epoch 50/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2509 - accuracy: 0.8963 - val_loss: 0.2403 - val_accuracy: 0.9065\n",
      "Epoch 51/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2524 - accuracy: 0.8966 - val_loss: 0.2435 - val_accuracy: 0.9027\n",
      "Epoch 52/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2527 - accuracy: 0.8969 - val_loss: 0.2367 - val_accuracy: 0.9054\n",
      "Epoch 53/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2501 - accuracy: 0.8958 - val_loss: 0.2382 - val_accuracy: 0.9004\n",
      "Epoch 54/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2500 - accuracy: 0.8972 - val_loss: 0.2382 - val_accuracy: 0.8991\n",
      "Epoch 55/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2511 - accuracy: 0.8988 - val_loss: 0.2381 - val_accuracy: 0.9030\n",
      "Epoch 56/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2495 - accuracy: 0.8976 - val_loss: 0.2401 - val_accuracy: 0.9073\n",
      "Epoch 57/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2504 - accuracy: 0.8987 - val_loss: 0.2366 - val_accuracy: 0.9050\n",
      "Epoch 58/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2507 - accuracy: 0.8976 - val_loss: 0.2376 - val_accuracy: 0.9109\n",
      "Epoch 59/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2496 - accuracy: 0.8996 - val_loss: 0.2436 - val_accuracy: 0.8955\n",
      "Epoch 60/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2528 - accuracy: 0.8970 - val_loss: 0.2388 - val_accuracy: 0.9067\n",
      "Epoch 61/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2525 - accuracy: 0.8941 - val_loss: 0.2403 - val_accuracy: 0.9084\n",
      "Epoch 62/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2517 - accuracy: 0.8969 - val_loss: 0.2398 - val_accuracy: 0.9029\n",
      "Epoch 63/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2530 - accuracy: 0.8978 - val_loss: 0.2400 - val_accuracy: 0.9033\n",
      "Epoch 64/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2489 - accuracy: 0.8979 - val_loss: 0.2352 - val_accuracy: 0.9081\n",
      "Epoch 65/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2495 - accuracy: 0.8958 - val_loss: 0.2418 - val_accuracy: 0.9030\n",
      "Epoch 66/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2499 - accuracy: 0.8991 - val_loss: 0.2377 - val_accuracy: 0.8982\n",
      "Epoch 67/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2500 - accuracy: 0.8972 - val_loss: 0.2384 - val_accuracy: 0.9071\n",
      "Epoch 68/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2516 - accuracy: 0.8969 - val_loss: 0.2371 - val_accuracy: 0.9025\n",
      "Epoch 69/100\n",
      "852/852 [==============================] - 1s 1ms/step - loss: 0.2511 - accuracy: 0.8949 - val_loss: 0.2390 - val_accuracy: 0.9002\n",
      "Epoch 70/100\n",
      "761/852 [=========================>....] - ETA: 0s - loss: 0.2496 - accuracy: 0.8986"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "if( True ):\n",
    "    # Load the datasets\n",
    "    data1 = pd.read_csv('EEG_mouse_data_1.csv')\n",
    "    data2 = pd.read_csv('EEG_mouse_data_2.csv')\n",
    "\n",
    "    # Combine and preprocess the data\n",
    "    data_combined = pd.concat([data1, data2])\n",
    "    data_combined['state'] = data_combined['state'].replace({'n': 0, 'r': 0, 'w': 1})\n",
    "    X = data_combined.drop('state', axis=1)\n",
    "    y = data_combined['state']\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Feature selection with RFE\n",
    "    model = LogisticRegression(max_iter=10000)\n",
    "    rfe = RFE(estimator=model, n_features_to_select=25)\n",
    "    X_rfe = rfe.fit_transform(X_scaled, y)\n",
    "\n",
    "    y_keras = y.to_numpy()\n",
    "\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    history_list = []\n",
    "    trained_mlps = []\n",
    "\n",
    "    bestmodel = None\n",
    "    bestAccuracy = 0\n",
    "\n",
    "    for train_index, test_index in kf.split(X_rfe):\n",
    "\n",
    "        print(len(train_index))\n",
    "\n",
    "        mlp = create_model(X_rfe.shape[1])\n",
    "\n",
    "        # Les données doivent être divisées selon les indices définis par KFold\n",
    "        X_train_kf, X_test_kf = X_rfe[train_index], X_rfe[test_index]\n",
    "        y_train_kf, y_test_kf = y_keras[train_index], y_keras[test_index]\n",
    "\n",
    "        history = mlp.fit(\n",
    "            X_train_kf, y_train_kf,\n",
    "            validation_data=(X_test_kf, y_test_kf),\n",
    "            epochs=100, verbose=1\n",
    "        )\n",
    "\n",
    "        print(f\"Accuracy: {history.history['val_accuracy'][-1]:.2f}\")\n",
    "\n",
    "        history_list.append(history)\n",
    "        trained_mlps.append(mlp)\n",
    "\n",
    "        if history.history['val_accuracy'][-1] > bestAccuracy:\n",
    "            bestAccuracy = history.history['val_accuracy'][-1]\n",
    "            bestmodel = mlp\n",
    "else :\n",
    "\n",
    "    # Get the highest float value from the filenames\n",
    "    highest_float = float('-inf')\n",
    "    files = os.listdir('.')\n",
    "\n",
    "    model_file = [fichier for fichier in os.listdir('.') if fichier.startswith('m_')]\n",
    "    model_file_float = [fichier[2:] for fichier in model_file]\n",
    "    for file in model_file_float:\n",
    "        float_value = float(file)\n",
    "        if float_value > highest_float:\n",
    "            highest_float = float_value\n",
    "\n",
    "    # Load the model from the highest float filename\n",
    "    model_filename = 'm_' + str(highest_float)\n",
    "    model = keras.models.load_model(model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: m_0.9005946516990662/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: m_0.9005946516990662/assets\n"
     ]
    }
   ],
   "source": [
    "bestmodel.save(f'm_{bestAccuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
